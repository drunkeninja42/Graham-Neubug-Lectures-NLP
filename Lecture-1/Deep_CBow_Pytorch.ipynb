{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f6-d-UlP-ee7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time \n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to read in the corpus\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "t2i = defaultdict(lambda: len(t2i))\n",
        "UNK = w2i[\"\"]\n",
        "def read_dataset(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            tag, words = line.lower().strip().split(\" ||| \")\n",
        "            yield ([w2i[x] for x in words.split(\" \")], t2i[tag])\n",
        "\n",
        "# Read in the data\n",
        "train = list(read_dataset(\"train.txt\"))\n",
        "w2i = defaultdict(lambda: UNK, w2i)\n",
        "dev = list(read_dataset(\"test.txt\"))\n",
        "# nwords = len(w2i)\n",
        "# ntags = len(t2i)"
      ],
      "metadata": {
        "id": "oUQOll0v-zug"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepCBowClassifier(nn.Module):\n",
        "  def __init__(self,nwords , ntags , hidden_layers , hidden_size , emb_size):\n",
        "    super(DeepCBowClassifier , self).__init__()\n",
        "    self.nlayers = hidden_layers\n",
        "\n",
        "    #layers\n",
        "    self.embedding = nn.Embedding(nwords , emb_size)\n",
        "    nn.init.xavier_uniform_(self.embedding.weight)\n",
        "\n",
        "    self.linear_layers = nn.ModuleList([\n",
        "        nn.Linear((emb_size if i == 0 else hidden_size), hidden_size)\n",
        "        for i in range(hidden_layers)\n",
        "    ])\n",
        "    for i in range(hidden_layers):\n",
        "      nn.init.xavier_uniform_(self.linear_layers[i].weight)\n",
        "\n",
        "    self.output_layer = nn.Linear(hidden_size , ntags)\n",
        "    nn.init.xavier_uniform_(self.output_layer.weight)\n",
        "  \n",
        "  def forward(self , words):\n",
        "    emb = self.embedding(words)\n",
        "    emb_sum = torch.sum(emb , dim = 0)\n",
        "    h = emb_sum.view(1,-1)\n",
        "    for i in range(self.nlayers):\n",
        "      h = torch.tanh(self.linear_layers[i](h))\n",
        "    out = self.output_layer(h)\n",
        "    return out"
      ],
      "metadata": {
        "id": "nP4uMzdX_Qae"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMB_SIZE = 64\n",
        "HID_SIZE = 64\n",
        "NLAYERS = 2\n",
        "nwords = len(w2i)\n",
        "ntags = len(t2i)\n",
        "print(nwords , ntags)\n",
        "model = DeepCBowClassifier(nwords, ntags, NLAYERS, EMB_SIZE, HID_SIZE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2zIa8FiCkBL",
        "outputId": "e711db08-e0c8-4976-ee54-8d9ba341e414"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18648 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type = torch.LongTensor\n",
        "\n",
        "for ITER in range(100):\n",
        "    # Perform training\n",
        "    random.shuffle(train)\n",
        "    train_loss = 0.0\n",
        "    start = time.time()\n",
        "    for words, tag in train:\n",
        "        words = torch.tensor(words).type(type)\n",
        "        tag = torch.tensor([tag]).type(type)\n",
        "        scores = model(words)\n",
        "        loss = criterion(scores, tag)\n",
        "        train_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (\n",
        "                ITER, train_loss/len(train), time.time()-start))\n",
        "    # Perform testing\n",
        "    test_correct = 0.0\n",
        "    for words, tag in dev:\n",
        "        words = torch.tensor(words).type(type)\n",
        "        scores = model(words)[0].detach().cpu().numpy()\n",
        "        predict = np.argmax(scores)\n",
        "        if predict == tag:\n",
        "            test_correct += 1\n",
        "    print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))\n"
      ],
      "metadata": {
        "id": "TMjmXHgpCqt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0FWGK5CC3K2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}