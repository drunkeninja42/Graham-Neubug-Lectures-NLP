{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "fKxWpwbspffp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import collections \n",
        "import nltk\n",
        "import re\n",
        "from scipy.sparse import dok_matrix\n",
        "import sklearn\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = \"Game of Thrones Thrones is an amazing tv series!\"\n",
        "doc2 = \"Game of Thrones is the best tv series!\"\n",
        "doc3 = \"Game of Thrones is so great\""
      ],
      "metadata": {
        "id": "qNHW2dETp7E0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_doc1 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc1.lower()).split() #removing punctuations, smallcase the words and creating list of invidual words using split\n",
        "l_doc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnRIBxuEqtp4",
        "outputId": "41d391ac-11bc-4b12-8123-434dd75fe5d3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['game', 'of', 'thrones', 'thrones', 'is', 'an', 'amazing', 'tv', 'series']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l_doc2 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc1.lower()).split()\n",
        "l_doc3 = re.sub(r\"[^a-zA-Z0-9]\", \" \", doc1.lower()).split()"
      ],
      "metadata": {
        "id": "eNNP0HyNrJaa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_doc2\n",
        "l_doc3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vabhenrdrt4q",
        "outputId": "3acb4087-7988-4d96-8995-ca36ba63a4ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['game', 'of', 'thrones', 'is', 'an', 'amazing', 'tv', 'series']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(line):\n",
        "  return re.sub(r\"[^a-zA-Z0-9]\", \" \", line.lower()).split()\n",
        "\n",
        "def build_feature_map(X):\n",
        "  word_types = set() #set whereever unique words is asked\n",
        "  for datum in X:\n",
        "    for word in tokenize(datum):\n",
        "      word_types.add(word)\n",
        "  # print(word_types)\n",
        "  return {word : i for i , word in enumerate(word_types)}\n",
        "\n",
        "def calculateBOW(wordset,l_doc):\n",
        "  tf_diz = dict.fromkeys(wordset,0)\n",
        "  print(tf_diz)\n",
        "  for word in l_doc:\n",
        "      tf_diz[word]=l_doc.count(word)\n",
        "  return tf_diz\n",
        "\n",
        "#another way of extracting features or calculating the count of each word is using scipy\n",
        "#sparse matrix using dok_matrix \n",
        "def extract_features(word_to_idx , X):\n",
        "  features = dok_matrix((len(X) , len(word_to_idx)))\n",
        "  for i in range(len(X)):\n",
        "    for word in tokenize(X[i]):\n",
        "      if word in word_to_idx:\n",
        "        features[i , word_to_idx[word]]+=1 \n",
        "  return features\n"
      ],
      "metadata": {
        "id": "uAMzOEUgrxKN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = [\n",
        "    \"Game of Thrones Thrones is an amazing tv series!\",\n",
        "    \"Game of Thrones is the best tv series!\",\n",
        "    \"Game of Thrones is so great\"\n",
        "]\n",
        "wordset = build_feature_map(sample_data)\n",
        "print(wordset)\n",
        "# calculateBOW(wordset , l_doc1)\n",
        "extract_features(wordset , sample_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQg2r9zVtsb6",
        "outputId": "28e592e5-04e9-4348-f2db-09b8efd3b996"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'thrones': 0, 'series': 1, 'is': 2, 'so': 3, 'great': 4, 'an': 5, 'best': 6, 'the': 7, 'game': 8, 'amazing': 9, 'tv': 10, 'of': 11}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x12 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 22 stored elements in Dictionary Of Keys format>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_XY_data(filename):\n",
        "    X_data = []\n",
        "    Y_data = []\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f:\n",
        "            label, text = line.strip().split(' ||| ')\n",
        "            X_data.append(text)\n",
        "            Y_data.append(int(label))\n",
        "    return X_data, Y_data"
      ],
      "metadata": {
        "id": "VVupxlDK0iSX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train ,Y_train = read_XY_data(\"train.txt\")\n",
        "X_test , Y_test = read_XY_data(\"test.txt\")"
      ],
      "metadata": {
        "id": "xGr295Ty48mF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build feature map according to training data\n",
        "wordset = build_feature_map(X_train)\n",
        "X_train_vec = extract_features(wordset , X_train)\n",
        "X_test_vec = extract_features(wordset, X_test)"
      ],
      "metadata": {
        "id": "NEI_Wccj5UH4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = sklearn.linear_model.LogisticRegression(tol = 1e1)\n",
        "clf.fit(X_train_vec, Y_train)\n",
        "print (clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5hycrMo5XG9",
        "outputId": "4a8e8bbf-7597-4a6e-eec4-c87d129ffaa3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(tol=10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = clf.predict(X_test_vec)\n",
        "print(sklearn.metrics.classification_report(Y_test, predictions, target_names=['-1','0','1']))\n",
        "print(sklearn.metrics.confusion_matrix(Y_test, predictions, labels=[-1,0, 1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imtrr4fy6WZL",
        "outputId": "cd6a0395-3afa-4d69-f9ff-d349aaafff46"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.68      0.69      0.69       912\n",
            "           0       0.26      0.17      0.21       389\n",
            "           1       0.69      0.78      0.73       909\n",
            "\n",
            "    accuracy                           0.63      2210\n",
            "   macro avg       0.54      0.55      0.54      2210\n",
            "weighted avg       0.61      0.63      0.62      2210\n",
            "\n",
            "[[629 116 167]\n",
            " [169  67 153]\n",
            " [125  79 705]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymqH67O16yTy"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bErfMWAF7f0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}